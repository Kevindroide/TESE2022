{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis\n",
    "\n",
    "## Pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\"\n",
    "\n",
    "df= pd.read_csv(url, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.head(n) muestra las primera n columnas del archivo (default 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.tail(n) muestra las ultimas n columnas del archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para escribir el archivo en nuestro dominio podemos agregar un path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/kevindroide/NDS/DataScience/TESE2022/automovile.csv\"\n",
    "#df.to_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Pandas ofrece lecturas y exportaciones de archivos csv, json, Excel, sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    pd.read_csv() ----- df.to_csv()\n",
    "    pd.read_json() ---- df.to_json()\n",
    "    pd.read_excel() ---- df.to_excel()\n",
    "    pd.read_sql() ---- df.to_sql()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El DataSet no tiene argumentos en header, por lo que podemos agregarlos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\", \"num-of-doors\",\"body-style\",\n",
    "         \"drive-wheels\",\"engine-location\",\"wheel-base\", \"length\",\"width\",\"height\",\"curb-weight\",\"engine-type\",\n",
    "         \"num-of-cylinders\", \"engine-size\",\"fuel-system\",\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\n",
    "         \"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]\n",
    "print(\"Headers:\\n\", headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = headers\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.describe() ignora las columnas vacias, para incluir todas agregamos parametros\n",
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se agregan tres parametros más a la estadística:\n",
    "\n",
    "\n",
    "unique corresponde a la cantidad de objetos distintos en la columna\n",
    "\n",
    "top corresponde al objeto más frecuente en la columna\n",
    "\n",
    "freq corresponde a la frecuencia en la que el objeto top aparece\n",
    "\n",
    "(NaN significa Not a Nomber)\n",
    "\n",
    "Otro método para revisar el DataSet es df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para deshacernos de los valores nulos podemoa usar df.dropna()\n",
    "\n",
    "df.drop() hace lo mismo pero con columnas enteras\n",
    "\n",
    "El metodo por sí solo no genera cambios en el DataFrame, para ello se agrega el parámetro inplace=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"price\"], axis=0)\n",
    "#en axis, 0 representa la fila/row y 1 representa la columna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener el DataType del DataFrame podemos usar df.dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hace tambien de descripcion de headers específicos como parametros en un arreglo del DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"length\", \"compression-ratio\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remplazar valores\n",
    "Para esto se usa el método df.replace(valor_a_remplazar, nuevo_valor)\n",
    "\n",
    "Es comun que si un valor está extraviado se use el valor promedio de la columna, entonces calculamos el promedio de la \"normalized-losses\"\n",
    "\n",
    "np.nan() retorna los valores NaN\n",
    "\n",
    "Reemplazamos los valores perdidos de ? para poder hacer un promedio\n",
    "\n",
    "El metodo replace() da una salida al reemplazamiento pero no modifica el Dataframe, por lo tanto, se hace una asignación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df[\"normalized-losses\"] = df[\"normalized-losses\"].replace(\"?\",np.NaN).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"normalized-losses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtenemos el promedio y remplazamos\n",
    "prom = df[\"normalized-losses\"].mean().astype(int)\n",
    "print(prom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"normalized-losses\"]= df[\"normalized-losses\"].replace(np.NaN,prom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora puede verse que los valores nulos \"?\" fueron reemplazados por el valor promedio 122"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para identificar el tipo de dato:\n",
    "    df.dtype()\n",
    "### Para convertir a un tipo de dato\n",
    "    df.astype()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización\n",
    "Tres formas de normalización      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i)    $x_{nor}$ = ${x_i}\\over{x_{max}} $  (Simple Feature scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ii) $ x_{nor}$ = ${x_i - x_{min}} \\over {x_{max} - x_{min}} $ (Min-Max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iii) $x_{nor}$ = ${x_i -\\mu} \\over {\\sigma}$ (Z-score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Python podemos escribir:\n",
    "\n",
    ">df[\"feature\"] = df[\"feature\"]/df[\"feature\"].max()\n",
    "    \n",
    ">df[\"feature\"] = (df[\"feature\"] - df[\"feature\"].min())/(df[\"feature\"].max - df[\"feature\"].min())\n",
    "\n",
    ">df[\"feature\"] = (df[\"feature\"] - df[\"feature\"].mean())/df[\"feature\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Binning\n",
    "Binning es cuando se categorizan valores de una variable en acotaciones\n",
    "   \n",
    "   i.e. edad: [0,6],[7,13],[14,18],[19,30]..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar el df anterior para categorizar precios como: Low, Normal, High\n",
    "\n",
    "Para ello creamos particiones de los precios usando Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\"price\" es de tipo object, por lo que reemplazaremos los valores\n",
    "\n",
    "df[\"price\"] = df[\"price\"].replace(\"?\",np.NaN).astype(float)\n",
    "df[\"price\"].dropna(axis=0)\n",
    "df[\"price\"] = df[\"price\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(min(df[\"price\"]), max(df[\"price\"]), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_bins = [\"Low\",\"Medium\",\"High\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar el metodo de pandas pd.cut() para hacer el arreglo de los bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"price-binned\"] =  pd.cut(df[\"price\"],bins,labels=price_bins,include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"price-binned\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables categoricas a numericas\n",
    "Eventualmente encontramos variables categoricas, como el tipo de combustible, para hacer conteo de cada una de las categorias podemos usar\n",
    ">pd.get_dummies() \n",
    "\n",
    "Este proceso se conoce como \n",
    "### One-Hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df[\"fuel-type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Herramientas de visualización\n",
    "## matplotlib\n",
    "\n",
    "Es una librería para la creación de graficas\n",
    "\n",
    "Podemos empezar con un histograma de los precios de los autos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(df[\"price\"], bins=10, color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos agregar notaciones a nuestras graficas para un mejor entendimiento de lo que se grafica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df[\"price\"], bins=15, color=\"green\", alpha=0.5)\n",
    "plt.title(\"Distribución de precios de autos en USD\")\n",
    "plt.xlabel(\"Precio en USD\")\n",
    "plt.ylabel(\"Frecuencia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos también agrupar y acomodar datos de interés, como el tipo de cuerpo.\n",
    "\n",
    "También podemos hacer calculos sobre los grupos extraidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_body = df.groupby(\"body-style\")[\"price\"].mean()\n",
    "df_body.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, también podemos graficar sobre nuestras nuevas agrupaciones.\n",
    "\n",
    "Usaremos una grafica de barras para visualizar los precios promedio por tipo de cuerpo del auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_body.plot(kind=\"bar\", width=0.5, color=\"green\", title=\"Precios promedio por tipo de cuerpo\", xlabel=\"Tipo de cuerpo\", ylabel=\"Precios promedio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_body[\"frecuency\"] = df[\"body-style\"].value_counts().sort_index()\n",
    "df_body[\"frecuency\"].plot(kind=\"pie\", figsize=(5, 6), autopct='%1.1f%%', title=\"Body styles in dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"horsepower\"] = df[\"horsepower\"].replace(\"?\",np.NaN).astype(float)\n",
    "df[\"horsepower\"].dropna(axis=0, inplace=True)\n",
    "df[\"peak-rpm\"] = df[\"peak-rpm\"].replace(\"?\",np.NaN).astype(float)\n",
    "df[\"peak-rpm\"].dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_price = (df[\"price\"] - df[\"price\"].min()) / (df[\"price\"].max() - df[\"price\"].min())\n",
    "#norm_price = (df[\"price\"] - df[\"price\"].mean())/(df[\"price\"].std())\n",
    "df.sort_values(\"horsepower\").plot(\n",
    "        kind=\"scatter\",\n",
    "        x=\"horsepower\",\n",
    "        y=\"peak-rpm\",\n",
    "        alpha=0.3,\n",
    "        s=norm_price*3000+10,\n",
    "        xlim=(25,300),\n",
    "        figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"drive-wheels\")[\"price\"].mean().plot(kind=\"bar\", width=0.5, color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Exploratory Data Analysis\n",
    "### Estadística descriptiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar el método df.describe() para obtener infromación estadística del DataSet, sin embargo, ésta función ignora los elementos NaN.\n",
    "\n",
    "Sin embargo, podemos describir datos categóricos usando el método value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"fuel-type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplots\n",
    "### Diagrama de cajas\n",
    "Con Boxplots podemos hacer comparaciones en la distribución de la información\n",
    "\n",
    "Hagamos otro DataFrame con los datos del tipo de tracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_wheels_counts= df[\"drive-wheels\"].value_counts()\n",
    "drive_wheels_counts.rename({\"drive-wheels\":\"value_counts\"},inplace=True)\n",
    "drive_wheels_counts.index.name=\"drive-wheels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_wheels_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "sns.boxplot(x=\"drive-wheels\", y=\"price\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un grafico de cajas:\n",
    "\n",
    "    -La linea del centro de la caja representa la mediana. Una mitad de los datos está por debajo de este valor, y la otra por encima. \n",
    "    \n",
    "    -Los extremos de arriba y abajo de la caja indican los cuantiles, o percentiles, 25 y 75. Estos dos cuantiles también se conocen como cuartiles, porque separan cuartos (25 %) de los datos. La longitud de la caja es la diferencia entre estos dos percentiles y se conoce como rango intercuartílico (IQR).\n",
    "\n",
    "    -Las líneas que se extienden desde la caja se llaman bigotes. Los bigotes representan la varianza esperada de los datos.\n",
    "\n",
    "    -Si hay datos que queden por encima o por debajo de los extremos de los bigotes, se los representa con puntos. Estos puntos se conocen como valores atípicos. Un valor atípico es el que supera la varianza esperada. Merece la pena revisar estos puntos de datos para aclarar si son atípicos o erróneos.\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así podemos ver que existe una variación en el precio más grande entre los sistemas de llantas traseras que entre los sistemas de cuatro llantas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Plot\n",
    "Ayudan a detectar si existe correlación entre los datos, cuenta con dos variables:\n",
    "\n",
    "    Predictor/Independent (La que nos interesa si tiene correlación)\n",
    "    Target/dependent (La que intentamos predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df[\"engine-size\"]\n",
    "x=df[\"price\"]\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.title(\"Relacíon Tamaño del motor VS Precio\")\n",
    "plt.ylabel(\"Tamaño del motor\")\n",
    "plt.xlabel(\"Precio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, podemos ver que a mayor precio, existe una tendencia a mayor tamaño del motor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping\n",
    "Pandas contiene el método df.Groupby(), éste puede aplicarse a variables categóricas.\n",
    "Ésta crea grupos de datos en subsets incluyendo las distintas categorias de la variable, que puede ser una o varias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemo así extraer columnas de interes para analizar si el tipo de sistema de llantas tiene relación con el precio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wheels = df[[\"drive-wheels\", \"body-style\",  \"price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grupo =  df_wheels.groupby([\"drive-wheels\",\"body-style\"], as_index=False).mean()\n",
    "df_grupo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta tabla no es tan fácil de leer a simple vista, por lo que podemos usar el método df.pivot()\n",
    "para poder reordenar el indice y las columnas de interés:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = df_grupo.pivot(index=\"drive-wheels\", columns=\"body-style\")\n",
    "df_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap\n",
    "\n",
    "Heatmap es un método de matplotlib que toma una tabla rectangular y les asigna un color vasado en el valor de cada elemento. Así pueden analizarse facilmente un conjunto de variables a la vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.pcolor(df_grupo[\"body-style\"], df_grupo[\"drive-wheels\"], np.array(df_grupo[\"price\"]), cmap=\"RdBu\")\n",
    "plt.pcolor(df_pivot, cmap=\"RdBu\")\n",
    "plt.colorbar()\n",
    "plt.yticks(np.arange(0.5, len(df_pivot.index), 1), df_pivot.index)\n",
    "plt.xticks(np.arange(0.5, len(df_pivot.columns), 1), df_pivot.columns.get_level_values(1))\n",
    "plt.show(6,5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA\n",
    "Analysis of Variance\n",
    "El método ANOVA encuentra la correlación entre distintos grupos de una variable categórica. Este método retorna dos elementos:\n",
    "\n",
    "## $ F_{statistic} $ = $ varianza_{grupo} \\over varianza_{grupos} $\n",
    "\n",
    "    F-statistic score: Variación entre el promedio del grupo divividido por la varianza\n",
    "\n",
    "        -Un valor grande de F implica una gran varianza entre la categoría y la variable objetivo\n",
    "        \n",
    "        -Un valor pequeño de F implica poca varianza entre la variable categórica y la variable objetivo\n",
    "        \n",
    "#### Entre mayor sea el valor de F-statistic, mayor diferencia habrá entre los grupos \n",
    "\n",
    "    \n",
    "    p-value: Valor de confianza, el valor de esto sintetiza la reelevancia de la estadística\n",
    "\n",
    "#### $ {p} < 0.05 $ Podemos concluir que hay una diferencia estadística significativa entre los promedios de cada grupo\n",
    "\n",
    "#### $ {p} >> 0.05 $ Sigifica que no existen suficientes datos para concluir la diferencia significativa entre los promedios de cada grupo\n",
    "    \n",
    "Para éste método es necesario la librería SciPy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "df_anova = df[[\"make\", \"price\"]]\n",
    "grouped_anova = df_anova.groupby([\"make\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_results = stats.f_oneway(grouped_anova.get_group(\"honda\")[\"price\"], grouped_anova.get_group(\"subaru\")[\"price\"])\n",
    "anova_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'statistic' representa el valor de F, que en este caso es menor a 1, entonces no hay mucha diferencia entre los precios de ambos grupos\n",
    "\n",
    "#### Pero p >> 0.05, entonces no se puede comprobar la hipótesis de que los promedios de los grupos son similares.\n",
    "\n",
    "Comparando ahora contra la marca \"jaguar\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_results = stats.f_oneway(grouped_anova.get_group(\"honda\")[\"price\"], grouped_anova.get_group(\"jaguar\")[\"price\"])\n",
    "anova_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Podemos ahora ver un valor de F muy grande y un valor de p muy pequeño, por lo que se concluye que existe gran varianza entre lo precios de Honda y Jaguar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation\n",
    "\n",
    "Mide en qué forma distintas variables son independientes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"engine-size\", y=\"price\", data=df, color=\"green\")\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.ylim(0,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver una tendencia en una pendiente positiva.\n",
    "\n",
    "Hagamos otro análisis entre galones por litro y el precio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"highway-mpg\", y=\"price\", data=df)\n",
    "plt.ylim(0,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos ver una pendiente negativa: entre más millas por galón consume un auto, menor tiende a ser su precio.\n",
    "\n",
    "Así podemos decir que existe una relación lineal negativa entre mpg y el precio\n",
    "\n",
    "Podemos tambien descartar otras relaciones que no muestren una tendencia, por ejemplo rpm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"peak-rpm\" es de tipo object, por lo que lo convertimos a tipo int\n",
    "#df[\"peak-rpm\"] = df[\"peak-rpm\"].replace(\"?\",0).astype(int)\n",
    "#df[\"peak-rpm\"] = df[\"peak-rpm\"].astype(int)\n",
    "\n",
    "#Ajustamos tambien los 0 al promedio para no tener incongruencias\n",
    "rpm_prom = df[\"peak-rpm\"].mean().astype(int)\n",
    "df[\"peak-rpm\"] = df[\"peak-rpm\"].replace(np.NaN,rpm_prom).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"peak-rpm\", y=\"price\", data=df)\n",
    "plt.ylim(0,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el valor de RPM no tiene una correlación evidente, por lo que los datos de RPM no son efectivos para predecir precios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson Correlation\n",
    "Mide una magnitud de correlación en dos prámetros:\n",
    "    \n",
    "    Coeficiente de correlación:\n",
    "-Valores cercanos a 1 indican una grande correlación positiva\n",
    "\n",
    "-Valores cercanos a -1 indican una grande correlación negativa\n",
    "\n",
    "-Valores cercanos a 0 indican que no hay correlación entre la variabes\n",
    "\n",
    "    P-value:\n",
    "Mide qué tan certero es el coeficiente de correlación anterior\n",
    "\n",
    "P-value < 0.001 indican gran certeza\n",
    "\n",
    "P-value < 0.05 indican certeza moderada\n",
    "\n",
    "P-value < 0.1 indican certeza débil\n",
    "\n",
    "P-value > 0.1 indican que no hay certeza en el resultado\n",
    "\n",
    "\n",
    "\n",
    "### Así podemos decir que una correlación es fuerte si el coeficiente es cercano a 1 o a -1 y que el P-value es menor a 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"horsepowe\" es de tipo object, por lo que lo convertimos a tipo int\n",
    "#df[\"horsepower\"] = df[\"horsepower\"].replace(\"?\",0).astype(int)\n",
    "#df[\"horsepower\"] = df[\"horsepower\"].astype(int)\n",
    "\n",
    "#Ajustamos tambien los 0 al promedio para no tener incongruencias\n",
    "rpm_prom = df[\"horsepower\"].mean().astype(int)\n",
    "df[\"horsepower\"] = df[\"horsepower\"].replace(np.NaN,rpm_prom).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"price\"].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"price\"] = df[\"price\"].apply(pd.to_numeric, errors = 'coerce')\n",
    "df.dropna(how='any', inplace=True)\n",
    "df[df[\"price\"].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pearson_coef, p_value = stats.pearsonr(df[\"horsepower\"], df[\"price\"])\n",
    "print(\"Pearson Coef: \", pearson_coef, \" P-value: \", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el Coeficiente de Pearson es 0.1, por lo que es cercano a 1, y el valor de p es muy muy pequeño, por lo que hay certeza en el resultado\n",
    "\n",
    "Puede entonces decirse que existe gran correlación positiva entre el \"horsepower\" y el precio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos también usar el método de pandas df.corr() para hacer una menos descriptiva pero más general de nuestro Dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"price\",\"horsepower\", \"engine-size\", \"compression-ratio\", \"city-mpg\",\"peak-rpm\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, en la primera fila podemos encontrar las correlaciones entre el precio y los otros atributos.\n",
    "\n",
    "Podemos decir con ésto que para el precio hay más reelevancia en el tamaño del motor que en las rpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(corr, xticklabels=corr.columns, \n",
    "            yticklabels=corr.columns, \n",
    "            annot=True,\n",
    "            cmap=sns.diverging_palette(220, 30, as_cmap=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresión lineal simple es un método para comprender la relación entre dos variables:\n",
    "    \n",
    "    Predictor/independiente: x\n",
    "    Target/dependiente: y\n",
    "    \n",
    "Deseamos encontrar una relación lineal entre ambas variables de la forma:\n",
    "\n",
    "# $y$ = $b_0 + b_1 x $\n",
    "\n",
    "El parámetro $b_0$ es la insersección, $b_1$ es la pendiente de la recta.\n",
    "\n",
    "Utilizaremos linear_model del paquete scikit-learn\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos las variables independiente y dependiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"highway-mpg\"]]\n",
    "Y = df[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El metodo lm.fit() para ajustar los parámetros del modelo y encontrar los parámetros $b_0, b_1$\n",
    "\n",
    "Podemos obtener la predicción con el método lm.predict(), cuya salida es un arreglo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit(X,Y)\n",
    "Yhat=lm.predict(X)\n",
    "print(X.size)\n",
    "print(Y.size)\n",
    "print(Yhat.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos encontrar la intersección $b_0$ usando lm.intercept_, y obtenemos $b_1$ usando lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"b_0 = \", lm.intercept_)\n",
    "print(\"b_1 = \",lm.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, la relación lineal quedará representada como\n",
    "\n",
    "    Precio = 38423.30 -(821.73)*highway-mpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Éste método permite encontrar la relación entre:\n",
    "\n",
    "    Una variable Target: y\n",
    "    \n",
    "    Dos o más variables Predictors: x\n",
    "    \n",
    "Si tuvieramos cuatro varirables predictorias, tendríamos una ecuación tal que:\n",
    "\n",
    "# $\\hat{Y}$ = $b_0 + b_1 x_1 + b_2 x_2 + b_3 x_3 + b_4 x_4 $\n",
    "\n",
    "Para extraer las variables que queremos predecir las guardamos en una variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = df[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']]\n",
    "lm.fit(Z,df[\"price\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lm.intercept_)\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lm.intercept_ representa la intersección, es decir, el término independiente de la relación lineal, mientras lm.coef_ representa la pendiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression plot\n",
    "\n",
    "Nos da un estimado de la relación de dos variables, la relevancia de la correlación y la direcciónn de la la relación. \n",
    "Para visualizarlo usaremos regplot() de seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"highway-mpg\", y=\"price\", data=df)\n",
    "plt.ylim(0,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual plot\n",
    "\n",
    "El residual plot representa el error entre los valores reales. El residuo representa la distancia entre el valor predecido Yhat y el valor correcto Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(x=\"highway-mpg\", y=\"price\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distrubition plot\n",
    "\n",
    "Podemos hacer una gráfica de la dristribución entre los valores predecidos con los valores reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "ax1 = sns.distplot(df[\"price\"], hist=False, color=\"r\", label=\"Valor real\")\n",
    "sns.distplot(Yhat, hist=False, color=\"b\", label=\"Prediccion\", ax=ax1)\n",
    "plt.title(\"Valores reales contra predicción\")\n",
    "plt.xlabel(\"Precio\")\n",
    "plt.ylabel(\"Proporción del auto\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polonomial regression\n",
    "\n",
    "Cuando el modelo no puede predecirse con un modelo lineal podemos utilizar una regresión polinómica. Es práctica para adaptar modelos con curvaturas.\n",
    "\n",
    "    Regresión polinómica de orden n:\n",
    "$\\hat{Y}$ = $ b_0 + b_1 x_1 + b_2 {x_2}^2 + ... + b_n {x_n}^n $\n",
    "\n",
    "En python podemos usar numpy para ajustar modelos polinómicos usando np.polyfit() y np.poly1d() para mostrarlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definiremos una función para poder graficar polinomios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotPolly(model, independent_variable, dependent_variabble, Name):\n",
    "    x_new = np.linspace(15, 55, 100)\n",
    "    y_new = model(x_new)\n",
    "\n",
    "    plt.plot(independent_variable, dependent_variabble, '.', x_new, y_new, '-')\n",
    "    plt.title('Polynomial Fit with Matplotlib for Price ~ Length')\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor((0.898, 0.898, 0.898))\n",
    "    fig = plt.gcf()\n",
    "    plt.xlabel(Name)\n",
    "    plt.ylabel('Price of Cars')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[\"highway-mpg\"]\n",
    "y = df[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.polyfit(x,y,3)\n",
    "p = np.poly1d(f)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotPolly(p, x, y, \"Highway-mpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar \"preprocessing\" en sci-kit-learn para crear un objeto polinómico.\n",
    "\n",
    "El constructor toma el grado del polinomio como parámetro para después poder transformarlo en un objeto con fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "pr= PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "x_polly = pr.fit_transform(df[[\"horsepower\", \"curb-weight\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos normalizar cada atributo simultaneamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "SCALE = StandardScaler()\n",
    "\n",
    "SCALE.fit(df[[\"horsepower\", \"highway-mpg\"]])\n",
    "\n",
    "x_scale = SCALE.transform(df[[\"horsepower\", \"highway-mpg\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos simplificar éstos códigos usando Pipelines, que sigue los pasos:\n",
    "\n",
    "Normalización ---> Transformación Polinómica ---> Regresión Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "Input = [(\"scale\", StandardScaler()), (\"polynomial\", PolynomialFeatures(degree=3)), (\"model\", LinearRegression())]\n",
    "\n",
    "pipe = Pipeline(Input)\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(Z,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos una funcion para poder graficar nuestra regresión polinómica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "def PollyPlot(xtrain, xtest, y_train, y_test, lr,poly_transform):\n",
    "    width = 12\n",
    "    height = 10\n",
    "    plt.figure(figsize=(width, height))\n",
    "    \n",
    "    \n",
    "    #training data \n",
    "    #testing data \n",
    "    #lr:  linear regression object \n",
    "    #poly_transform:  polynomial transformation object \n",
    " \n",
    "    xmax=max([xtrain.values.max(), xtest.values.max()])\n",
    "\n",
    "    xmin=min([xtrain.values.min(), xtest.values.min()])\n",
    "\n",
    "    x=np.arange(xmin, xmax, 0.1)\n",
    "\n",
    "\n",
    "    plt.plot(xtrain, y_train, 'ro', label='Datos de entrenamiento')\n",
    "    plt.plot(xtest, y_test, 'go', label='Datos de prueba')\n",
    "    plt.plot(x, lr.predict(poly_transform.fit_transform(x.reshape(-1, 1))), label='Función de regresión', linewidth=2, color='blue',)\n",
    "    plt.ylim([-10000, 60000])\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend()\n",
    "    \n",
    "    return plt\n",
    "\n",
    "def DistributionPlot(RedFunction, BlueFunction, RedName, BlueName, Title):\n",
    "    width = 12\n",
    "    height = 10\n",
    "    plt.figure(figsize=(width, height))\n",
    "\n",
    "    ax1 = sns.distplot(RedFunction, hist=False, color=\"r\", label=RedName)\n",
    "    ax2 = sns.distplot(BlueFunction, hist=False, color=\"b\", label=BlueName, ax=ax1)\n",
    "\n",
    "    plt.title(Title)\n",
    "    plt.xlabel('Precio [USD]')\n",
    "    plt.ylabel('Proportion of Cars')\n",
    "\n",
    "def f(order, test_data):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=test_data, random_state=0)\n",
    "    pr = PolynomialFeatures(degree=order)\n",
    "    x_train_pr = pr.fit_transform(x_train[['horsepower']])\n",
    "    x_test_pr = pr.fit_transform(x_test[['horsepower']])\n",
    "    poly = LinearRegression()\n",
    "    poly.fit(x_train_pr,y_train)\n",
    "    PollyPlot(x_train[['horsepower']], x_test[['horsepower']], y_train,y_test, poly, pr)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo\n",
    "\n",
    "Son formas para evaluar qué tan preciso es el modelo que tenemos comparado con los valores reales. Dos métodos son importantes:\n",
    "\n",
    "    Mean Squared Error (MSE): Error cuadrático medio\n",
    "Debemos encontrar la diferencia entre los valores reales (y) y los valores predecidos (Yhat) y elevarla al cuadrado. Posteriormente se obtiene el promedio del cuadrado de los errores.\n",
    "    \n",
    "    R-squared (R^2):\n",
    "También llamado coeficiente de determinación, mide qué tan cercanos son los valores reales contra los predecidos. Representa el porcentaje de la variación del valor real que puede ser explicado por el modelo\n",
    "    \n",
    "# $R^2$ = $ ({1} - {{ MSE_{regression-line}} \\over {MSE_{average-data}}}) $\n",
    "    \n",
    "    \n",
    "Para obtener el MSE podemos usar el método mean_squared_error(valor real, valor predecido): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(df[\"price\"], Yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor de $R^2$ lo podemos obtener usando el método lm.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[[\"highway-mpg\"]]\n",
    "Y=df[\"price\"]\n",
    "\n",
    "lm.fit(X,Y)\n",
    "\n",
    "lm.score(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto dice que el modelo lineal predice el 49.65% de la variación del precio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction and  decision making\n",
    "\n",
    "Determinaremos si un modelo es de fiar, para esto podemos utilizar visualización, métodos numéricos y comparación entre distintos modelos.\n",
    "\n",
    "Primero entrenamos el modelo con lm.fit() y después agregamos como parámetro el valor que queremos determinar en lm.predict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit(X,Y)\n",
    "lm.predict(X)[30] #Corresponde a una predicción del precio de un auto con 30 highway-mpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer método para visualizar y hacer un análisis del model es un RegressionPlot, pues puede apreciarse de una forma más clara la correspondencia de los valores.\n",
    "\n",
    "En un Resicual plot podemos aún confirmar el comportamiento de las gráficas: si podemos apreciar una curva, se sugiere un comportamiento no-lineal.\n",
    "\n",
    "Los Distribution plot son un buen método para evaluar múltiples variables.\n",
    "\n",
    "El MSE es intuitivo para determinar si el modelo es bueno o no, así como lo es también $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Evaluación y refinación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anteriormente hemos evaluado nuestros modelos en base a la información con la que fue entrenado. Sin embargo aún no hemos evaluado un modelo para predecir nueva información.\n",
    "\n",
    "Separar la información entre training/testing sets es algo importante para la evaluación del modelo. Usualmente, la gran mayoría de la información es usada para entrenar el modelo y sólo una pequeña parte es utilizada para testing.\n",
    "\n",
    "Por ejemplo, podemos dividir el 70% de un dataset para entrenar el modelo y el otro 30% para probarlo. Posteriormente construimos el modelo usando training data y usamos la testing data para medir la eficiencia del modelo. Una vez terminado el testing, podemos usar toda la información para darle un mejor desempeño."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una función popular para divivir un DataSet es la función train_test_split() en el paquete scikit-learn, que divide aleatoriamente la información que necesitamos. Por ejemplo:\n",
    "\n",
    "       x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=03, random_state=0)\n",
    "Donde x_data corresponde a la variable independiente, como los features del sistema, y y_data es el objetivo a predecir, como el precio. x_train, y_train corresponde al dataset para entrenar el modelo y x_test, y_test son para evaluar el modelo.\n",
    "test_size corresponde al percentaje del dataset para la evaluación. random_state es una semilla para la separación aleatoria.\n",
    "\n",
    "Generalization error es una medida para qué tan bien la información usada ayuda a predecir nueva información.\n",
    "\n",
    "Cross Validation es una métrica de evaluación de la información, tanto de la de entrenamiento como la de evaluación. Cross validation crea distintas particiones del dataframe y permuta el testing data para deducir si la información puede producir un buen desempeño:\n",
    "\n",
    "        scores = cross_val_score(lr, x_data, y_data, cv=3)\n",
    "lr representa \"linear regression\" como el tipo de modelo y cv corresponde a la cantidad de particiones que se harán. El retorno se expresa como un arreglo, sin embargo podemo usar no.mean().\n",
    "\n",
    "    yhat = cross_val_predict(lr2e, x_data, y_data, cv=3)\n",
    "Tiene la misma sintaxis pero no devuelve una evaluación del modelo, sino la misma predicción del modelo que medimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_data = df[\"price\"]\n",
    "x_data = df.drop(\"price\", axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.15, random_state=1)\n",
    "\n",
    "print(\"Número de datos en test: \", x_test.shape[0])\n",
    "print(\"Número de datos en train: \", x_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lre=LinearRegression()\n",
    "\n",
    "Rcross = cross_val_score(lre, x_data[['horsepower']], y_data, cv=4)\n",
    "Rcross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"El promedio de los 'folds'es: \", Rcross.mean(), \"y la desviación es: \" , Rcross.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "yhat = cross_val_predict(lre, x_data[[\"horsepower\"]], y_data, cv=4)\n",
    "\n",
    "yhat[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting, Underfitting and Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asumiremos que los training points vienen de un función polinómica de la forma\n",
    "\n",
    "$y(x)+ ruido$\n",
    "\n",
    "El objetivo de la seleccion de un modelo es encontrar el orden del polinomio que mejor predice la función. En el caso anteior de una función polinómica, un modelo lineal resulta vago para expresar correctamente la función\n",
    "\n",
    "Llamaremos Undefitting cuando un modelo es demasiado simple como para describir propiamente un sistema.\n",
    "\n",
    "Al aumentar el polinomio del modelo lineal podemos hacer una aproximación mas certera del modelo, sin embargo, sucede también que un polinomio de grado muy alto puede predecir exactamente los puntos de prueba, pero falla en describir la función.\n",
    "\n",
    "Llamamos entonces Overfitting cuando el modelo se ajusta más a los puntos de ruido que a la función que buscamos, ésto es común en las regiones con pocos data points.\n",
    "\n",
    "Una buena forma de ubicar las regiiones de Underfitting y Overfitting es con los valores $R^2$. Podemos usar el siguiente código para hacer reconocimiento de los valores de $R^2$ según el orden del polinomio: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LinearRegression()\n",
    "\n",
    "#lr.fit(x_train[[\"horsepower\"]], y_train)\n",
    "\n",
    "Rsqu_test = []\n",
    "order = [1,2,3,4,5]\n",
    "for n in order:\n",
    "    pr=PolynomialFeatures(degree=n)\n",
    "    x_train_pr = pr.fit_transform(x_train[[\"curb-weight\"]])\n",
    "    x_test_pr = pr.fit_transform(x_test[[\"curb-weight\"]])\n",
    "    lr.fit(x_train_pr, y_train)\n",
    "    Rsqu_test.append(lr.score(x_test_pr, y_test))\n",
    "#PollyPlot(x_train[[\"curb-weight\"]], x_test[[\"curb-weight\"]], y_train, y_test, lr, pr, n)\n",
    "interact(f, order=(1,10,1), test_data=(0.05,0.95,0.05))\n",
    "for n in order:\n",
    "    print('Polynomial degree:' , n, 'R-squared:', Rsqu_test[n-1])\n",
    "\n",
    "print('Max score:', max(Rsqu_test), 'with polynomial degree:', order[Rsqu_test.index(max(Rsqu_test))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(order, Rsqu_test)\n",
    "plt.xlabel('order')\n",
    "plt.ylabel('R^2')\n",
    "plt.title('R^2 por grado polinomial')\n",
    "plt.text(2.2, 0.835, 'Maximum R^2 ')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression\n",
    "\n",
    "Éste método nos previene de hacer Overfitting. Éste método crea una nueva variable \"Alpha\", la cual regula los coeficientes de nuestro polinomio. Éste es un parámetro que escogemos antes de entrenar nuestro modelo.\n",
    "\n",
    "Para hacer una predicción usando ridge regression podemos usar un codigo como el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "pr=PolynomialFeatures(degree=2)\n",
    "x_train_pr=pr.fit_transform(x_train[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg','normalized-losses','symboling']])\n",
    "x_test_pr=pr.fit_transform(x_test[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg','normalized-losses','symboling']])\n",
    "\n",
    "RigeModel = Ridge(alpha=1)\n",
    "\n",
    "RigeModel.fit(x_train_pr,y_train)\n",
    "\n",
    "yhat =  RigeModel.predict(x_test_pr)\n",
    "\n",
    "print('predicted:', yhat[0:4])\n",
    "print('test set :', y_test[0:4].values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos crear un loop para encontrar el valor de Alpha más eficiente para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "Rsqu_test = []\n",
    "Rsqu_train = []\n",
    "dummy1 = []\n",
    "Alpha = 10 * np.array(range(0,1000))\n",
    "pbar = tqdm(Alpha)\n",
    "\n",
    "for alpha in pbar:\n",
    "    RigeModel = Ridge(alpha=alpha) \n",
    "    RigeModel.fit(x_train_pr, y_train)\n",
    "    test_score, train_score = RigeModel.score(x_test_pr, y_test), RigeModel.score(x_train_pr, y_train)\n",
    "    \n",
    "    pbar.set_postfix({\"Test Score\": test_score, \"Train Score\": train_score})\n",
    "\n",
    "    Rsqu_test.append(test_score)\n",
    "    Rsqu_train.append(train_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos graficar el comportamiento de estos valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 12\n",
    "height = 10\n",
    "plt.figure(figsize=(width, height))\n",
    "\n",
    "plt.plot(Alpha,Rsqu_test, 'b',label='Test')\n",
    "plt.plot(Alpha,Rsqu_train, 'r', label='Train')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('R^2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "\n",
    "Éste método nos permite hacer un análisis de múltiples parámetros en pocas lineas de código.\n",
    "Parámetros como \"Alpha\" no son parte del proceso de entrenamiento del modelo, por lo que se les refiere como hyperparámetros.\n",
    "\n",
    "Grid search toma los modelos u objetos de los que se tenga interés y los evalua bajo distintos hyperparámetros, posteriormente hace un cálculo del MSE y $R^2$ para poder escoger los hiperparámetros más apropiados.\n",
    "\n",
    "El valor del grid search es una lista de python que contiene un diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "x_data = df[[\"horsepower\", \"curb-weight\", \"engine-size\", \"highway-mpg\"]]\n",
    "\n",
    "y_data = df[\"price\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.15, random_state=1)\n",
    "\n",
    "\n",
    "parameters1 = [{\"alpha\":[0.001, 0.1, 1, 10 , 100, 1000, 10000, 100000],\"normalize\":[True, False]}]\n",
    "\n",
    "RR=Ridge()\n",
    "\n",
    "Grid1= GridSearchCV(RR,parameters1,cv=4)\n",
    "\n",
    "Grid1.fit(x_data,y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BestRR = Grid1.best_estimator_\n",
    "print(BestRR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora predecimos sobre nuestros datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BestRR.score(x_test[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = Grid1.cv_results_\n",
    "\n",
    "scores[\"mean_test_score\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = BestRR.predict(x_test[['horsepower', 'curb-weight', 'engine-size', 'highway-mpg']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title = 'Distribution  Plot of  Predicted Value Using Training Data vs Training Data Distribution'\n",
    "DistributionPlot(y_test, yhat, \"Actual Values (Train)\", \"Predicted Values (Train)\", Title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('DS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c77ba1d199b1dde5235f968872b1242afb1c25c39b3775aedde9bd5b8017dd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
